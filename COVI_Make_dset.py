#!/usr/bin/env python2.7
import argparse, os
from collections import defaultdict
import COVIclientmodules.FsFormats as FsF

def make_covi_dataset(annot_1D_roi, inflated_surface, matrix_file_name,
    matrix_corr_1D, path):
    '''
    annot_1D_roi: an .annot.1D.roi file generated by SUMA_make_spec_*
    inflated_surface: An inflated FreeSurfer ASCII (.asc) surface
    matrix_file_name: the 1D results file from @ROI_Corr_Mat
    path: The path to write out the dataset
    '''
    try:
        annot_1D_roi = FsF.read_annot_1D_roi(annot_1D_roi)
        # Create ROI=>Node map for create_clust_file
        roi_node_map = defaultdict(list)
        for node, roi, r, g, b in annot_1D_roi:
            roi_node_map[roi].append(node)
        all_nodes_xyz = FsF.read_surface(inflated_surface)["nodes"]
        corr_matrix = FsF.read_ROI_Corr_Matrix(matrix_file_name,
            roi_node_map.keys())

    except (ValueError, IOError) as e:
        print e
        
    try:
        create_stat_files(corr_matrix, path)
        create_clust_file(roi_node_map, all_nodes_xyz, path)
    except IOError as e:
        print "Could not write out dataset:"
        print e


def create_stat_files(corr_matrix, path):
    '''
    Create a .stat.1D file for each cluster.
    corr_matrix: The 1D correlation matrix generated by @ROI_Corr_Mat
    '''
    for roi in corr_matrix:
        stat_fi = open(os.path.join(path,"%s.stat.1D"%(roi)), 'w')
        stat_fi.writelines(corr_matrix[roi])
        stat_fi.write('\n')


def create_clust_file(roi_node_map, all_nodes_xyz, path):
    '''
    Creates the cluster.1D file necessary for a COVI dataset.

    annot_1D_roi: the .annot.1D.roi files for both hemispheres,
        parsed by FsFormats.read_annot_1D_roi
    all_nodes_xyz: the "nodes" list from an inflated surface asc file
        parsed by FsFormats.read_surface
    '''
    clust_fi = open(os.path.join(path,"clusters.1D"%(roi)), 'w')
    for roi in roi_node_map:
        nodes = roi_node_map[roi]
        nodes_xyz = {}
        [nodes_xyz.__setitem__(node, all_nodes_xyz[node])
            for node in nodes]

        cent_x = [1./len(nodes)*i[0] for i in nodes_xyz.itervalues()]
        cent_y = [1./len(nodes)*i[1] for i in nodes_xyz.itervalues()]
        cent_z = [1./len(nodes)*i[2] for i in nodes_xyz.itervalues()]

        cent = [cent_x, cent_y, cent_z]

        min_dist = 10**5
        cent_node = 0
        for i in nodes_xyz:
            dist = distance(nodes_xyz[i], cent_node)
            if dist < min_dist:
                min_dist = dist
                cent_node = i

        clust_fi.write('%i\n'%(roi))
        clust_fi.write('%i\n'%(cent_node))
        del nodes_xyz[cent_node]
        for i in nodes_xyz:
            clust_fi.write('%i\n'%(i))
        clust_fi.write('\n')

def writeable_dir(op):
    if os.path.isdir(op) and os.access(op, os.W_OK):
        return op
    else:
        try:
            os.mkdir(op)
        except os.error:
            raise argparse.ArgumentError(
                "%s is not a writable directory, "%(str(op))+
                "and could not be created.")

def afni_head_brik(op):
    if (os.access(op+'.HEAD', os.R_OK) or os.path.isdir(op+'.head', os.R_OK) and
        os.access(op+'.BRIK', os.R_OK) or os.path.isdir(op+'.brik', os.R_OK)): 
        return op
    else:
        raise argparse.ArgumentError(
            "%s is missing a HEAD or BRIK file. "%(str(op)))

if __name__ == '__main__':
    # Parse arguments
    '''
    TODO:
    -Parse arguments
    -Parse the spec file
    -tgz the SurfVol, spec file, and attached surfaces
    Arguments:
    -op <output path>
    -spec <lh or rh spec>
    -sv <SurfVol>
    -matrix <1D covariance matrix>
    -annot1droi <.annot.1D.roi file>
    '''

    parser = argparse.ArgumentParser(
        description="COnnectome VIsualizer dataset creation script")
    """
    parser.add_argument('-spec', action='store', type=file,
        help="<left or right hemisphere spec file>", required=True)
    """
    parser.add_argument('-inf', '--inflated', action='store', type=file,
        help="<inflated surface file>", required=True)
    parser.add_argument('-sv', '--SurfVol',  action='store', type=afni_head_brik,
        help="<SurfVol file>", required=True)
    parser.add_argument('-mat', '--matrix', action='store', type=file,
        help="<a .corr.1D file output from @ROI_Corr_Mat>", required=True)
    parser.add_argument('-roi', '--annot1droi', action='store', type=file,
        help="<the .annot.1D.roi file, output by SUMA_make_spec_FS "+
        "for the left or right hemisphere>", required=True)
    parser.add_argument('-prefix', type=writeable_dir, action='store',
        help="<the new dataset's name>", required=True)
    results = parser.parse_args()
    """
    for i in results:
        print i
        print results.getattr(results, i)
    """
